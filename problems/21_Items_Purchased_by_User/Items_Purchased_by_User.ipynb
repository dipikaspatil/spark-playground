{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4118c1d-e70e-4c13-ab6a-35bf4120f59d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseException",
     "evalue": "\n[PARSE_SYNTAX_ERROR] Syntax error at or near end of input. SQLSTATE: 42601 (line 1, pos 24)\n\n== SQL ==\ntry_element_at(items, -1\n------------------------^^^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParseException\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 90\u001b[39m\n\u001b[32m     84\u001b[39m columns = [\u001b[33m\"\u001b[39m\u001b[33mcustomer_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mitems\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     86\u001b[39m df = spark.createDataFrame(data, columns)\n\u001b[32m     88\u001b[39m df_result = (\n\u001b[32m     89\u001b[39m   \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marray_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mitems\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[43m  \u001b[49m\u001b[43m.\u001b[49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlast_item\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtry_element_at(items, -1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m   .withColumn(\u001b[33m\"\u001b[39m\u001b[33munique_count\u001b[39m\u001b[33m\"\u001b[39m, F.size(F.array_distinct(F.col(\u001b[33m\"\u001b[39m\u001b[33mitems\u001b[39m\u001b[33m\"\u001b[39m))))\n\u001b[32m     92\u001b[39m   .drop(\u001b[33m\"\u001b[39m\u001b[33mitems\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     93\u001b[39m )\n\u001b[32m     95\u001b[39m df_result.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.5/libexec/lib/python3.13/site-packages/pyspark/sql/classic/dataframe.py:1623\u001b[39m, in \u001b[36mDataFrame.withColumn\u001b[39m\u001b[34m(self, colName, col)\u001b[39m\n\u001b[32m   1618\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[32m   1619\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[32m   1620\u001b[39m         errorClass=\u001b[33m\"\u001b[39m\u001b[33mNOT_COLUMN\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1621\u001b[39m         messageParameters={\u001b[33m\"\u001b[39m\u001b[33marg_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcol\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33marg_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col).\u001b[34m__name__\u001b[39m},\n\u001b[32m   1622\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1623\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m.sparkSession)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.5/libexec/lib/python3.13/site-packages/py4j/java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.5/libexec/lib/python3.13/site-packages/pyspark/errors/exceptions/captured.py:288\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    284\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    287\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    290\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mParseException\u001b[39m: \n[PARSE_SYNTAX_ERROR] Syntax error at or near end of input. SQLSTATE: 42601 (line 1, pos 24)\n\n== SQL ==\ntry_element_at(items, -1\n------------------------^^^\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "You are given a dataset containing information about customers and their list of purchased items stored in an array column. Your task is to:\n",
    "\n",
    "Find the size of the array for each row\n",
    "Find the last element of the array\n",
    "Find the count of unique elements in the array\n",
    "Input Schema & Example\n",
    "Column Name\tData Type\n",
    "customer_id\tINT\n",
    "items\tARRAY<STRING>\n",
    "Example Input Table\n",
    "customer_id\titems\n",
    "1\t[\"apple\", \"banana\", \"apple\"]\n",
    "2\t[\"pen\", \"pencil\", \"ink\"]\n",
    "3\t[]\n",
    "Output Schema\n",
    "Column Name\tData Type\n",
    "customer_id\tINT\n",
    "array_size\tINT\n",
    "last_item\tSTRING\n",
    "unique_count\tINT\n",
    "Example Output Table\n",
    "customer_id\tarray_size\tlast_item\tunique_count\n",
    "1\t3\tapple\t2\n",
    "2\t3\tink\t3\n",
    "3\t0\tnull\t0\n",
    "Explanation\n",
    "For customer_id = 1:\n",
    "\n",
    "[\"apple\", \"banana\", \"apple\"] has size 3\n",
    "Last element is apple\n",
    "Unique elements are apple, banana → count = 2\n",
    "For customer_id = 2:\n",
    "\n",
    "Size = 3\n",
    "Last element = ink\n",
    "Unique count = 3\n",
    "For customer_id = 3:\n",
    "\n",
    "Size = 0\n",
    "No last element → null\n",
    "Unique count = 0\n",
    "Starter Code\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "data = [\n",
    "    (1, [\"apple\", \"banana\", \"apple\"]),\n",
    "    (2, [\"pen\", \"pencil\", \"ink\"]),\n",
    "    (3, []),\n",
    "    (4, [\"milk\", \"bread\", \"milk\", \"butter\"]),\n",
    "    (5, [\"apple\", \"orange\", \"banana\", \"orange\" , \"apple\"]),\n",
    "    (6, [\"pen\", \"pen\"]),\n",
    "    (7, [\"mobile\"])\n",
    "]\n",
    "\n",
    "columns = [\"customer_id\", \"items\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Your logic goes here to create df_result\n",
    "\n",
    "df_result.show(truncate=False)\n",
    "\n",
    "'''\n",
    "\n",
    "# Initialize Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName('Spark Playground').getOrCreate()\n",
    "\n",
    "data = [\n",
    "    (1, [\"apple\", \"banana\", \"apple\"]),\n",
    "    (2, [\"pen\", \"pencil\", \"ink\"]),\n",
    "    (3, []),\n",
    "    (4, [\"milk\", \"bread\", \"milk\", \"butter\"]),\n",
    "    (5, [\"apple\", \"orange\", \"banana\", \"orange\" , \"apple\"]),\n",
    "    (6, [\"pen\", \"pen\"]),\n",
    "    (7, [\"mobile\"])\n",
    "]\n",
    "\n",
    "columns = [\"customer_id\", \"items\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "df_result = (\n",
    "  df.withColumn(\"array_size\", F.size(F.col(\"items\")))\n",
    "  .withColumn(\"last_item\", F.expr(\"try_element_at(items, -1\"))\n",
    "  .withColumn(\"unique_count\", F.size(F.array_distinct(F.col(\"items\"))))\n",
    "  .drop(\"items\")\n",
    ")\n",
    "\n",
    "df_result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
