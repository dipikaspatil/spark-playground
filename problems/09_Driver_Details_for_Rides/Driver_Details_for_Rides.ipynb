{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b052b5a-2ada-440f-b01b-e250a0b5ec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+-----------+---------+\n",
      "|ride_id|driver_id|driver_name|fare_amount|   status|\n",
      "+-------+---------+-----------+-----------+---------+\n",
      "|      1|      101|       Alex|      300.0|available|\n",
      "|      3|      101|       Alex|      220.0|available|\n",
      "|      7|      101|       Alex|      275.0|available|\n",
      "|      2|      102|        Sam|      150.0| off_duty|\n",
      "|      6|      102|        Sam|      180.0| off_duty|\n",
      "|      4|      103|       Rita|      500.0|available|\n",
      "|      8|      103|       Rita|      330.0|available|\n",
      "|      5|      104|       John|      100.0|suspended|\n",
      "|      9|      105|      Priya|      400.0|available|\n",
      "|     10|      106|     Ramesh|      210.0| off_duty|\n",
      "+-------+---------+-----------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "You are given two datasets:\n",
    "\n",
    "rides – containing ride-level data such as pickup time, fare amount, and distance.\n",
    "drivers – containing driver information including name, status, and rating.\n",
    "Your task is to:\n",
    "\n",
    "Join both datasets using the driver_id field.\n",
    "Select the following columns from the joined data: ride_id, driver_id, driver_name, fare_amount, status.\n",
    "Input Schema\n",
    "rides schema\n",
    "Column Name\tData Type\n",
    "ride_id\tInteger\n",
    "driver_id\tInteger\n",
    "rider_id\tInteger\n",
    "fare_amount\tDouble\n",
    "distance_km\tDouble\n",
    "Example rides table\n",
    "ride_id\tdriver_id\trider_id\tfare_amount\tdistance_km\n",
    "1\t101\t201\t300.0\t12.4\n",
    "2\t102\t202\t150.0\t8.0\n",
    "3\t101\t203\t220.0\t10.5\n",
    "drivers schema\n",
    "Column Name\tData Type\n",
    "driver_id\tInteger\n",
    "name\tString\n",
    "status\tString\n",
    "rating\tDouble\n",
    "Example drivers table\n",
    "driver_id\tname\tstatus\trating\n",
    "101\tAlex\tavailable\t4.8\n",
    "102\tSam\toff_duty\t4.6\n",
    "Output Schema\n",
    "Column Name\tData Type\n",
    "ride_id\tInteger\n",
    "driver_id\tInteger\n",
    "driver_name\tString\n",
    "fare_amount\tDouble\n",
    "status\tString\n",
    "Example Output Table\n",
    "ride_id\tdriver_id\tdriver_name\tfare_amount\tstatus\n",
    "1\t101\tAlex\t300.0\tavailable\n",
    "2\t102\tSam\t150.0\toff_duty\n",
    "3\t101\tAlex\t220.0\tavailable\n",
    "Starter Code\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, IntegerType,\n",
    "    StringType, DoubleType\n",
    ")\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "rides_data = [\n",
    "    (1, 101, 201, 300.0, 12.4),\n",
    "    (2, 102, 202, 150.0, 8.0),\n",
    "    (3, 101, 203, 220.0, 10.5),\n",
    "    (4, 103, 204, 500.0, 15.6),\n",
    "    (5, 104, 205, 100.0, 5.0),\n",
    "    (6, 102, 206, 180.0, 9.2),\n",
    "    (7, 101, 207, 275.0, 11.8),\n",
    "    (8, 103, 208, 330.0, 13.0),\n",
    "    (9, 105, 209, 400.0, 14.0),\n",
    "    (10, 106, 210, 210.0, 9.0),\n",
    "]\n",
    "\n",
    "drivers_data = [\n",
    "    (101, \"Alex\", \"available\", 4.8),\n",
    "    (102, \"Sam\", \"off_duty\", 4.6),\n",
    "    (103, \"Rita\", \"available\", 4.9),\n",
    "    (104, \"John\", \"suspended\", 3.2),\n",
    "    (105, \"Priya\", \"available\", 4.5),\n",
    "    (106, \"Ramesh\", \"off_duty\", 4.3),\n",
    "]\n",
    "\n",
    "rides_schema = StructType([\n",
    "    StructField(\"ride_id\", IntegerType(), True),\n",
    "    StructField(\"driver_id\", IntegerType(), True),\n",
    "    StructField(\"rider_id\", IntegerType(), True),\n",
    "    StructField(\"fare_amount\", DoubleType(), True),\n",
    "    StructField(\"distance_km\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "drivers_schema = StructType([\n",
    "    StructField(\"driver_id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"rating\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "rides_df = spark.createDataFrame(rides_data, schema=rides_schema)\n",
    "drivers_df = spark.createDataFrame(drivers_data, schema=drivers_schema)\n",
    "\n",
    "# Your logic here\n",
    "# Save the final output DataFrame as df_result\n",
    "\n",
    "display(df_result)\n",
    "'''\n",
    "# Initialize Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, IntegerType,\n",
    "    StringType, DoubleType\n",
    ")\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName('Spark Playground').getOrCreate()\n",
    "\n",
    "rides_data = [\n",
    "    (1, 101, 201, 300.0, 12.4),\n",
    "    (2, 102, 202, 150.0, 8.0),\n",
    "    (3, 101, 203, 220.0, 10.5),\n",
    "    (4, 103, 204, 500.0, 15.6),\n",
    "    (5, 104, 205, 100.0, 5.0),\n",
    "    (6, 102, 206, 180.0, 9.2),\n",
    "    (7, 101, 207, 275.0, 11.8),\n",
    "    (8, 103, 208, 330.0, 13.0),\n",
    "    (9, 105, 209, 400.0, 14.0),\n",
    "    (10, 106, 210, 210.0, 9.0),\n",
    "]\n",
    "\n",
    "drivers_data = [\n",
    "    (101, \"Alex\", \"available\", 4.8),\n",
    "    (102, \"Sam\", \"off_duty\", 4.6),\n",
    "    (103, \"Rita\", \"available\", 4.9),\n",
    "    (104, \"John\", \"suspended\", 3.2),\n",
    "    (105, \"Priya\", \"available\", 4.5),\n",
    "    (106, \"Ramesh\", \"off_duty\", 4.3),\n",
    "]\n",
    "\n",
    "rides_schema = StructType([\n",
    "    StructField(\"ride_id\", IntegerType(), True),\n",
    "    StructField(\"driver_id\", IntegerType(), True),\n",
    "    StructField(\"rider_id\", IntegerType(), True),\n",
    "    StructField(\"fare_amount\", DoubleType(), True),\n",
    "    StructField(\"distance_km\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "drivers_schema = StructType([\n",
    "    StructField(\"driver_id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"rating\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "rides_df = spark.createDataFrame(rides_data, schema=rides_schema)\n",
    "drivers_df = spark.createDataFrame(drivers_data, schema=drivers_schema)\n",
    "\n",
    "df_result = (\n",
    "  rides_df.join(drivers_df, on=\"driver_id\", how=\"inner\")\n",
    "  .select(\n",
    "    \"ride_id\",\n",
    "    \"driver_id\",\n",
    "    F.col(\"name\").alias(\"driver_name\"),\n",
    "    \"fare_amount\",\n",
    "    \"status\"\n",
    "  )\n",
    ")\n",
    "\n",
    "# Display the final DataFrame\n",
    "df_result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
