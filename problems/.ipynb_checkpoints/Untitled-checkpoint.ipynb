{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e38c505-a47e-45f7-a2ce-f6849cef5248",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Problem - \n",
    "Load and Transform Data\n",
    "You need to process a customer dataset to identify high-value customers. Specifically, you will:\n",
    "\n",
    "Read data from a CSV file with inferSchema option as true.\n",
    "Filter customers with a purchase amount more than 100 USD.\n",
    "Further filter to include only customers aged 30 or above.\n",
    "Use display(df) to show the final DataFrame.\n",
    "Input\n",
    "File Path:\n",
    "/datasets/customers.csv\n",
    "\n",
    "Schema:\n",
    "\n",
    "Column\tType\n",
    "customer_id\tinteger\n",
    "name\tstring\n",
    "email\tstring\n",
    "age\tinteger\n",
    "purchase_amount\tdouble\n",
    "Example Data:\n",
    "\n",
    "customer_id\tname\temail\tage\tpurchase_amount\n",
    "1\tAlice Johnson\talice@email.com\t25\t150.50\n",
    "2\tBob Smith\tbob@email.com\t32\t200.00\n",
    "3\tCharlie Brown\tcharlie@email.com\t29\t75.00\n",
    "4\tDiana Prince\tdiana@email.com\t40\t120.00\n",
    "5\tEvan Davis\tevan@email.com\t35\t90.00\n",
    "Output\n",
    "Call display function:\n",
    "Use display(df) to show the final DataFrame. Make sure the schema is correct.\n",
    "\n",
    "Schema:\n",
    "\n",
    "Column\tType\n",
    "customer_id\tinteger\n",
    "name\tstring\n",
    "purchase_amount\tdouble\n",
    "Example Data:\n",
    "\n",
    "customer_id\tname\tpurchase_amount\n",
    "2\tBob Smith\t200.00\n",
    "4\tDiana Prince\t120.00\n",
    "Explanation:\n",
    "\n",
    "The output DataFrame df_result includes customers who have a purchase amount of at least 100 USD and are aged 30 or above.\n",
    "In the example, Bob Smith and Diana Prince meet these criteria, so they are included in the result.\n",
    "'''\n",
    "\n",
    "# Initialize Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "spark = SparkSession.builder.appName('Spark Playground').getOrCreate()\n",
    "\n",
    "df_result = (\n",
    "  spark.read\n",
    "  .option(\"inferSchema\", True)\n",
    "  .option(\"header\", True)\n",
    "  .csv(\"/datasets/customers.csv\")\n",
    "  .filter(col(\"purchase_amount\") > 100)\n",
    "  .filter(col(\"age\") > 30)\n",
    "  .select(\"customer_id\", \"name\", \"purchase_amount\")\n",
    ")\n",
    "\n",
    "# Display the final DataFrame using the display() function.\n",
    "display(df_result)\n",
    "\n",
    "'''\n",
    "Bonus Challenge: Can you solve this using Spark SQL and temporary views?\n",
    "df = df_result = (\n",
    "  spark.read\n",
    "  .option(\"inferSchema\", True)\n",
    "  .option(\"header\", True)\n",
    "  .csv(\"/datasets/customers.csv\")\n",
    ")\n",
    "\n",
    "df.createOrReplaceTempView(\"customers\")\n",
    "df_result = spark.sql(\"\"\"\n",
    "SELECT customer_id, name, purchase_amount\n",
    "FROM customers\n",
    "WHERE purchase_amount > 100\n",
    "AND age > 30\n",
    "\"\"\"\n",
    ")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
