{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ab0c45-f6e5-4eb2-922b-20a42dbb8eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+\n",
      "|sales_category|avg_sales|\n",
      "+--------------+---------+\n",
      "|           Low|     76.4|\n",
      "|        Medium|   164.75|\n",
      "|          High|    233.5|\n",
      "+--------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "You are given a dataset containing sales information of different sales people. Each row in the dataset contains the salesperson’s ID, their name, and the sales amount. You need to write a PySpark program that performs the following tasks:\n",
    "\n",
    "Filter out records where sales are less than 50.\n",
    "\n",
    "Create a new column sales_category that categorizes sales into:\n",
    "\n",
    "Low (50–100)\n",
    "Medium (101–200)\n",
    "High (>200)\n",
    "Group the data by sales_category and calculate the average sales for each category.\n",
    "\n",
    "Input Schema & Example\n",
    "Column Name\tData Type\n",
    "id\tInteger\n",
    "name\tString\n",
    "sales\tDouble\n",
    "Example Input Table\n",
    "id\tname\tsales\n",
    "1\tAlice\t45\n",
    "2\tBob\t120\n",
    "3\tCarol\t75\n",
    "4\tDavid\t250\n",
    "5\tEve\t180\n",
    "Output Schema, Example & Explanation\n",
    "Column Name\tData Type\n",
    "sales_category\tString\n",
    "avg_sales\tDouble\n",
    "Example Output Table\n",
    "sales_category\tavg_sales\n",
    "Low\t75.0\n",
    "Medium\t150.0\n",
    "High\t250.0\n",
    "Explanation\n",
    "Records with sales < 50 are filtered out (so Alice’s record is removed).\n",
    "\n",
    "Carol (75) falls into Low, Bob (120) and Eve (180) fall into Medium, and David (250) falls into High.\n",
    "\n",
    "The averages are then computed per category:\n",
    "\n",
    "Low: (75) / 1 = 75.0\n",
    "Medium: (120 + 180) / 2 = 150.0\n",
    "High: (250) / 1 = 250.0\n",
    "Starter Code\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "data = [\n",
    "    (1, \"Alice\", 45),\n",
    "    (2, \"Bob\", 120),\n",
    "    (3, \"Carol\", 77),\n",
    "    (4, \"David\", 250),\n",
    "    (5, \"Eve\", 180),\n",
    "    (6, \"Jacob\", 30),\n",
    "    (7, \"Mike\", 90),\n",
    "    (8, \"Tim\", 65),\n",
    "    (9, \"Lukas\",159),\n",
    "    (10, \"Peter\", 217),\n",
    "    (11, \"Henry\", 100),\n",
    "    (12, \"Frida\", 200),\n",
    "    (13, \"Grisha\", 50)\n",
    "]\n",
    "\n",
    "columns = [\"id\", \"name\", \"sales\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Write your transformations here\n",
    "\n",
    "Use display(df_result) to show the final DataFrame.\n",
    "\n",
    "'''\n",
    "# Initialize Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName('Spark Playground').getOrCreate()\n",
    "\n",
    "data = [\n",
    "    (1, \"Alice\", 45),\n",
    "    (2, \"Bob\", 120),\n",
    "    (3, \"Carol\", 77),\n",
    "    (4, \"David\", 250),\n",
    "    (5, \"Eve\", 180),\n",
    "    (6, \"Jacob\", 30),\n",
    "    (7, \"Mike\", 90),\n",
    "    (8, \"Tim\", 65),\n",
    "    (9, \"Lukas\",159),\n",
    "    (10, \"Peter\", 217),\n",
    "    (11, \"Henry\", 100),\n",
    "    (12, \"Frida\", 200),\n",
    "    (13, \"Grisha\", 50)\n",
    "]\n",
    "\n",
    "columns = [\"id\", \"name\", \"sales\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Filter sales >= 50\n",
    "df_filtered = df.filter(F.col(\"sales\") >= 50)\n",
    "\n",
    "# Create new column sales_category\n",
    "df_with_category = (\n",
    "  df_filtered\n",
    "  .withColumn(\"sales_category\",\n",
    "              F.when((F.col(\"sales\") >= 50) & (F.col(\"sales\") <= 100), \"Low\")\n",
    "             .when((F.col(\"sales\") >= 101) & (F.col(\"sales\") <= 200), \"Medium\")\n",
    "             .otherwise(\"High\"))\n",
    ")\n",
    "\n",
    "# Aggregate\n",
    "df_result = (\n",
    "  df_with_category.groupBy(F.col(\"sales_category\"))\n",
    "  .agg(F.avg(F.col(\"sales\")).alias(\"avg_sales\"))\n",
    ")\n",
    "\n",
    "# Display result\n",
    "df_result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
