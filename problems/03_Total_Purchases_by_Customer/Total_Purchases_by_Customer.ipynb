{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed3351e-9b15-43a3-a07d-7b154d2c5804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n",
      "|customer_id|total_purchase|\n",
      "+-----------+--------------+\n",
      "|          1|           120|\n",
      "|          2|            30|\n",
      "|          3|            60|\n",
      "+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Problem Statement:\n",
    "Given a dataset of customer purchases, your task is to group the data by customer and calculate the total purchase amount for each customer. You will need to group by customer_id and sum up the purchase_amount for each individual.\n",
    "\n",
    "Order the result by customer_id\n",
    "\n",
    "Use display(df) to show the final DataFrame.\n",
    "\n",
    "Input\n",
    "File Path: /datasets/customer_purchases.csv\n",
    "Schema:\n",
    "customer_id: Integer\n",
    "name: String\n",
    "product_id: Integer\n",
    "purchase_date: Date\n",
    "purchase_amount: Integer\n",
    "Example Input\n",
    "customer_id\tname\tproduct_id\tpurchase_date\tpurchase_amount\n",
    "1\tJohn\t101\t2024-01-01\t50\n",
    "2\tAlice\t102\t2024-01-02\t30\n",
    "1\tJohn\t103\t2024-01-03\t70\n",
    "3\tBob\t104\t2024-01-04\t60\n",
    "Output\n",
    "Schema:\n",
    "customer_id: Integer\n",
    "total_purchase: Long\n",
    "Example Output\n",
    "customer_id\ttotal_purchase\n",
    "1\t120\n",
    "2\t30\n",
    "3\t60\n",
    "Explanation\n",
    "In this example, the output shows the total purchases made by each customer. Customer 1 (John) made two purchases totaling 120, customer 2 (Alice) made one purchase of 30, and customer 3 (Bob) made one purchase of 60.\n",
    "\n",
    "Use display(df) to show the final DataFrame.\n",
    "'''\n",
    "# Initialize Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum\n",
    "spark = SparkSession.builder.appName('Spark Playground').getOrCreate()\n",
    "\n",
    "df_raw = (\n",
    "  spark.read\n",
    "  .option(\"inferSchema\", True)\n",
    "  .option(\"header\", True)\n",
    "  .csv(\"./customer_purchases.csv\")\n",
    ")\n",
    "\n",
    "df_result = (\n",
    "  df_raw.groupBy(col(\"customer_id\"))\n",
    "  .agg(sum(\"purchase_amount\").alias(\"total_purchase\"))\n",
    "  .orderBy(col(\"customer_id\"))\n",
    ")\n",
    "\n",
    "# Display the final DataFrame using the display() function.\n",
    "df_result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
