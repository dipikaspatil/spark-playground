{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "562ade8f-6937-4cd0-8086-df5a54afb13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+------------------+--------------+---------------------+\n",
      "|  month|country|trans_count|trans_total_amount|approved_count|approved_total_amount|\n",
      "+-------+-------+-----------+------------------+--------------+---------------------+\n",
      "|2018-12|     US|          3|              3500|             2|                 1500|\n",
      "|2019-01|     DE|          2|              3800|             2|                 3800|\n",
      "|2019-01|     US|          2|              3500|             1|                 2000|\n",
      "|2019-02|     FR|          2|              3700|             1|                 2500|\n",
      "|2019-02|     US|          1|              3000|             1|                 3000|\n",
      "|2019-03|     DE|          1|              2200|             0|                    0|\n",
      "|2019-03|     FR|          1|              1000|             1|                 1000|\n",
      "+-------+-------+-----------+------------------+--------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "You are given a dataset containing transaction records with details about the transaction's country, state (approved/declined), amount, and date.\n",
    "\n",
    "Write a PySpark program to compute the following for each month and country:\n",
    "\n",
    "The total number of transactions (trans_count)\n",
    "The total amount of transactions (trans_total_amount)\n",
    "The number of approved transactions (approved_count)\n",
    "The total amount of approved transactions (approved_total_amount)\n",
    "Return the result sorted by month and country.\n",
    "\n",
    "Input Data\n",
    "The dataset contains the following columns:\n",
    "\n",
    "Column Name\tType\tDescription\n",
    "id\tint\tUnique transaction ID (Primary Key)\n",
    "country\tstring\tCountry where the transaction occurred\n",
    "state\tstring\tTransaction status (approved, declined)\n",
    "amount\tint\tTransaction amount\n",
    "trans_date\tdate\tDate when the transaction occurred\n",
    "The state column only has values \"approved\" or \"declined\".\n",
    "\n",
    "Example Input\n",
    "Transactions Dataset\n",
    "id\tcountry\tstate\tamount\ttrans_date\n",
    "121\tUS\tapproved\t1000\t2018-12-18\n",
    "122\tUS\tdeclined\t2000\t2018-12-19\n",
    "123\tUS\tapproved\t2000\t2019-01-01\n",
    "124\tDE\tapproved\t2000\t2019-01-07\n",
    "125\tUS\tapproved\t500\t2018-12-20\n",
    "126\tUS\tdeclined\t1500\t2019-01-05\n",
    "127\tDE\tapproved\t1800\t2019-01-10\n",
    "128\tFR\tdeclined\t1200\t2019-02-15\n",
    "129\tFR\tapproved\t2500\t2019-02-17\n",
    "130\tUS\tapproved\t3000\t2019-02-20\n",
    "131\tDE\tdeclined\t2200\t2019-03-05\n",
    "132\tFR\tapproved\t1000\t2019-03-10\n",
    "Expected Output\n",
    "month\tcountry\ttrans_count\tapproved_count\ttrans_total_amount\tapproved_total_amount\n",
    "2018-12\tUS\t3\t2\t3500\t1500\n",
    "2019-01\tDE\t2\t2\t3800\t3800\n",
    "2019-01\tUS\t2\t1\t3500\t2000\n",
    "2019-02\tFR\t2\t1\t3700\t2500\n",
    "2019-02\tUS\t1\t1\t3000\t3000\n",
    "2019-03\tDE\t1\t0\t2200\t0\n",
    "2019-03\tFR\t1\t1\t1000\t1000\n",
    "Starter Code\n",
    "Below is the starter code to create the input PySpark DataFrame:\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "from pyspark.sql.functions import col, to_date\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"MonthlyTransactionSummary\").getOrCreate()\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\"country\", StringType(), False),\n",
    "    StructField(\"state\", StringType(), False),\n",
    "    StructField(\"amount\", IntegerType(), False),\n",
    "    StructField(\"trans_date\", StringType(), False),  # Initially as String\n",
    "])\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    (121, \"US\", \"approved\", 1000, \"2018-12-18\"),\n",
    "    (122, \"US\", \"declined\", 2000, \"2018-12-19\"),\n",
    "    (123, \"US\", \"approved\", 2000, \"2019-01-01\"),\n",
    "    (124, \"DE\", \"approved\", 2000, \"2019-01-07\"),\n",
    "    (125, \"US\", \"approved\", 500, \"2018-12-20\"),\n",
    "    (126, \"US\", \"declined\", 1500, \"2019-01-05\"),\n",
    "    (127, \"DE\", \"approved\", 1800, \"2019-01-10\"),\n",
    "    (128, \"FR\", \"declined\", 1200, \"2019-02-15\"),\n",
    "    (129, \"FR\", \"approved\", 2500, \"2019-02-17\"),\n",
    "    (130, \"US\", \"approved\", 3000, \"2019-02-20\"),\n",
    "    (131, \"DE\", \"declined\", 2200, \"2019-03-05\"),\n",
    "    (132, \"FR\", \"approved\", 1000, \"2019-03-10\"),\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# Convert trans_date column to DateType\n",
    "df = df.withColumn(\"trans_date\", to_date(col(\"trans_date\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()\n",
    "Constraints\n",
    "The dataset is stored as a PySpark DataFrame.\n",
    "The trans_date column should be used to extract the month (formatted as YYYY-MM).\n",
    "The result should be grouped by month and country.\n",
    "Use display(df) to show the final DataFrame.\n",
    "'''\n",
    "# Initialize Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "\n",
    "spark = SparkSession.builder.appName('Spark Playground').getOrCreate()\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\"country\", StringType(), False),\n",
    "    StructField(\"state\", StringType(), False),\n",
    "    StructField(\"amount\", IntegerType(), False),\n",
    "    StructField(\"trans_date\", StringType(), False),  # Initially as String\n",
    "])\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    (121, \"US\", \"approved\", 1000, \"2018-12-18\"),\n",
    "    (122, \"US\", \"declined\", 2000, \"2018-12-19\"),\n",
    "    (123, \"US\", \"approved\", 2000, \"2019-01-01\"),\n",
    "    (124, \"DE\", \"approved\", 2000, \"2019-01-07\"),\n",
    "    (125, \"US\", \"approved\", 500, \"2018-12-20\"),\n",
    "    (126, \"US\", \"declined\", 1500, \"2019-01-05\"),\n",
    "    (127, \"DE\", \"approved\", 1800, \"2019-01-10\"),\n",
    "    (128, \"FR\", \"declined\", 1200, \"2019-02-15\"),\n",
    "    (129, \"FR\", \"approved\", 2500, \"2019-02-17\"),\n",
    "    (130, \"US\", \"approved\", 3000, \"2019-02-20\"),\n",
    "    (131, \"DE\", \"declined\", 2200, \"2019-03-05\"),\n",
    "    (132, \"FR\", \"approved\", 1000, \"2019-03-10\"),\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# Convert trans_date column to DateType\n",
    "df = df.withColumn(\"trans_date\", F.to_date(F.col(\"trans_date\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Aggregate data, groupBy month and country\n",
    "df_result = (\n",
    "  # Extract month in yyyy-MM format\n",
    "  df.withColumn(\"month\", F.date_format(F.col(\"trans_date\"), \"yyyy-MM\"))\n",
    "  .groupBy(\"month\", \"country\")\n",
    "  # Aggregate metrics\n",
    "  .agg(\n",
    "    F.count(\"*\").alias(\"trans_count\"),\n",
    "    F.sum(F.col(\"amount\")).alias(\"trans_total_amount\"),\n",
    "    F.sum(F.when(F.col(\"state\") == \"approved\", 1).otherwise(0)).alias(\"approved_count\"),\n",
    "    F.sum(F.when(F.col(\"state\") == \"approved\", F.col(\"amount\")).otherwise(0)).alias(\"approved_total_amount\")\n",
    "  )\n",
    "  .orderBy(\"month\", \"country\")\n",
    ")\n",
    "\n",
    "# Show result of dataframe\n",
    "df_result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
