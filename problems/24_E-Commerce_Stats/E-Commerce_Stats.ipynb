{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d8ae888-e54a-4e12-ba76-bb3e8a6ef04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/20 16:03:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/12/20 16:03:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'StructType' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Window \u001b[38;5;28;01mas\u001b[39;00m W\n\u001b[32m     54\u001b[39m spark = SparkSession.builder.appName(\u001b[33m'\u001b[39m\u001b[33mSpark Playground\u001b[39m\u001b[33m'\u001b[39m).getOrCreate()\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m products_schema = \u001b[43mStructType\u001b[49m([\n\u001b[32m     57\u001b[39m     StructField(\u001b[33m\"\u001b[39m\u001b[33mproduct_id\u001b[39m\u001b[33m\"\u001b[39m, IntegerType(), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     58\u001b[39m     StructField(\u001b[33m\"\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m\"\u001b[39m, StringType(), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     59\u001b[39m     StructField(\u001b[33m\"\u001b[39m\u001b[33mprice\u001b[39m\u001b[33m\"\u001b[39m, FloatType(), \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     60\u001b[39m ])\n\u001b[32m     62\u001b[39m products_data = [\n\u001b[32m     63\u001b[39m     (\u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mApparel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m25.99\u001b[39m),\n\u001b[32m     64\u001b[39m     (\u001b[32m2\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mApparel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m35.99\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m     (\u001b[32m5\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mApparel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m20.00\u001b[39m)\n\u001b[32m     68\u001b[39m ]\n\u001b[32m     70\u001b[39m products_df = spark.createDataFrame(products_data, schema=products_schema)\n",
      "\u001b[31mNameError\u001b[39m: name 'StructType' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "You have been given two DataFrames related to an E-commerce platform. The first contains information about the products and their categories, while the second contains information about the orders placed for these products. \n",
    "\n",
    "Calculate the average price and the total number of orders for each product category and display the result.\n",
    "\n",
    "Input DataFrames:\n",
    "\n",
    "products_df\n",
    "\n",
    "Column Name\tData Type\n",
    "product_id\tInteger\n",
    "category\tString\n",
    "price\tFloat\n",
    "orders_df\n",
    "\n",
    "Column Name\tData Type\n",
    "order_id\tInteger\n",
    "product_id\tInteger\n",
    "quantity\tInteger\n",
    "Output DataFrame:\n",
    "\n",
    "Column Name\tData Type\n",
    "category\tString\n",
    "avg_price\tFloat\n",
    "total_orders_count\tInteger\n",
    "Example\n",
    "products_df\n",
    "\n",
    "product_id\tcategory\tprice\n",
    "1\tApparel\t25.99\n",
    "2\tApparel\t35.99\n",
    "3\tFootwear\t50.00\n",
    "4\tFootwear\t75.00\n",
    "5\tApparel\t20.00\n",
    "orders_df\n",
    "\n",
    "order_id\tproduct_id\tquantity\n",
    "101\t1\t2\n",
    "102\t2\t1\n",
    "103\t1\t3\n",
    "104\t3\t1\n",
    "105\t4\t2\n",
    "output\n",
    "\n",
    "avg_price\tcategory\ttotal_orders_count\n",
    "29.323333\tApparel\t3\n",
    "62.500000\tFootwear\t2\n",
    "'''\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window as W\n",
    "from pyspark.sql import Window as W\n",
    "\n",
    "spark = SparkSession.builder.appName('Spark Playground').getOrCreate()\n",
    "\n",
    "products_schema = StructType([\n",
    "    StructField(\"product_id\", IntegerType(), True),\n",
    "    StructField(\"category\", StringType(), True),\n",
    "    StructField(\"price\", FloatType(), True)\n",
    "])\n",
    "\n",
    "products_data = [\n",
    "    (1, \"Apparel\", 25.99),\n",
    "    (2, \"Apparel\", 35.99),\n",
    "    (3, \"Footwear\", 50.00),\n",
    "    (4, \"Footwear\", 75.00),\n",
    "    (5, \"Apparel\", 20.00)\n",
    "]\n",
    "\n",
    "products_df = spark.createDataFrame(products_data, schema=products_schema)\n",
    "\n",
    "orders_schema = StructType([\n",
    "    StructField(\"order_id\", IntegerType(), True),\n",
    "    StructField(\"product_id\", IntegerType(), True),\n",
    "    StructField(\"quantity\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "orders_data = [\n",
    "    (101, 1, 2),\n",
    "    (102, 2, 1),\n",
    "    (103, 1, 3),\n",
    "    (104, 3, 1),\n",
    "    (105, 4, 2)\n",
    "]\n",
    "\n",
    "orders_df = spark.createDataFrame(orders_data, schema=orders_schema)\n",
    "\n",
    "df_result = (\n",
    "  products_df.join(orders_df, on = \"product_id\", how = \"inner\")\n",
    "  .groupBy(\"category\")\n",
    "  .agg(\n",
    "    F.count(\"order_id\").alias(\"total_orders_count\"),\n",
    "    F.avg(\"price\").alias(\"avg_price\")\n",
    "  )\n",
    ")\n",
    "\n",
    "# Display result\n",
    "df_result.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
